---
title: <font face="times">R programs for "Quantile autoregressive conditional heteroscedasticity"</font>
author:  <p align="right"><font face="times">Songhua Tan</font></p>
subtitle:  <p align="right"><font face="times">2022/10/01</font></p>
output: 
  html_document: 
    number_sections: yes
    theme: paper
    toc: yes
    toc_depth: 3
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE,comment='',cache = F)
```

# Preparation

```{r message=FALSE, warning=FALSE}
rm(list = ls())

# load the 'QGARCH' R-package. This package includes all the necessary functions in the empirical example of the manuscript
# If the R package are not installed on your computer, please use the following function to install it from the local file
# install.packages("QGARCH_1.0.0.tar.gz", repos = NULL, type = "source")
library(QGARCH)
```

# Real data

## Descriptive statistics

```{r message=FALSE, warning=FALSE}
# Load data from QGARCH package
data(SP500)
data_ana <- SP500[,c("date","close")] # Only extracts the date and closing price

head(data_ana)
```

```{r message=FALSE, warning=FALSE}
# Define the time range
t_start <- as.Date("2015-07-01")
t_end <- as.Date("2021-12-30")

index <- data_ana$date<=t_end & data_ana$date>=t_start # time index
data_ana_cut <- data_ana[index,"close"] # closing price
Y <- diff(log(data_ana_cut))*100 # log-return (%)
```

```{r message=FALSE, warning=FALSE}
# Data summary
length(Y) # the length of log-return (Note: the length of raw data = length(Y)+1)

summary_Y <- round(c(
  mean(Y),
  median(Y),
  sd(Y),
  mean((Y-mean(Y))^3)/sd(Y)^3,
  mean((Y-mean(Y))^4)/sd(Y)^4,
  min(Y),
  max(Y)
),3)
names(summary_Y) <- c("mean","median","sd","skewness","kurtosis","min","max")
summary_Y
```

## Model estimation

```{r message=FALSE, warning=FALSE}
# Model estimation at 5% quantile level
tau <- 0.05 # the specific quantile level

# Calculate the weight function
w <- weight_function_HeYi2021_cpp(Y = Y,C = quantile(Y,0.95)) 
w <- w/w[1] # regularization

fit <- fit1_optim(Y = Y,w = w,tau = 0.05) # model estimation
parm <- fit$par;parm # print the parameter estimation

ASD_QR(parm,Y,w,tau,"HS")$ASD # print the corresponding ASD
```


## Coefficient function estimation

In this subsection, we use the following procedure to plot a figure for estimates of coefficient functions:

1. Calculate the parameter estimates and ASDs of the fitted QGARCH(1,1) model at each quantile level. 

2. For comparison, fit a linear GARCH(1,1) model (2.4) with $x_t=y_t$ using Gaussian QMLE and estimate $Q_\tau(\varepsilon_t)$ using empirical quantile of $\{\hat{\varepsilon}_t\}$. Then $\left(\frac{a_0}{1-b_1}Q_\tau(\varepsilon_t),a_1Q_\tau(\varepsilon_t),b_1\right)$ can  be estimated at each quantile level.

3. Plot the estimated coefficient functions based on the QGARCH(1,1) model and linear GARCH(1,1) model (2.4).

```{r}
# Define the negative log-likelihood function of the linear GARCH(1,1) model (2.4), i.e. the ARCH(infty) model
# 
# @parm: Vector. (a_0,a_1,b_1)
# @Y: Vector. log-return
# 
Loss_ARCH_infty <- function(parm,Y){
  N <- length(Y)
  if(parm[1]<=0 | parm[2]<= 0|parm[3]<=0 | parm[3]>=1){
    return(1e+36)
  }else{
    b <- parm[2]*parm[3]^(1:(N-1)-1)
    h_t <- arch_fft(cst = parm[1]/(1-parm[3]),epsilon = Y[1:(N-1)],lambda = b)

    l <- log(h_t)+(Y[2:N])^2/(2*h_t^2)
    L <- sum(l)
    return(L)
  }
}

# Define the residual function of ARCH(infty) models
#
# @parm: Vector. (a_0,a_1,b_1)
# @Y: Vector. log-return
#
# return: Vector. Residuals
# 
res_ARCH_infty <- function(parm,Y){
  N <- length(Y)

  b <- parm[2]*parm[3]^(1:(N-1)-1)
  h_t <- arch_fft(cst = parm[1]/(1-parm[3]),epsilon = Y[1:(N-1)],lambda = b)

  res <- array(dim = c(N))
  res[1] <- Y[1]/sd(Y)
  res[2:N] <- Y[2:N]/h_t

  return(res)
}

# Define the estimating function of ARCH(infty) models using Gaussian QMLE
#
# @Y: Vector. log-return
# @fixTau: Vector. Multiple quantile levels
# 
# return: List. 
#         - ARCH_par: Parameter estimation of ARCH(infty) models
#         - Q_tau: Quantile of residuals
# 
fit_ARCHinfty <- function(Y,fixTau){
  # obtain an initial value based on the MLE of GARCH(1,1) model
  r <- sqrt(abs(Y))*((Y>=0)-(Y<0))
  spec=ugarchspec(variance.model = list(model = "sGARCH", garchOrder = c(1, 1)),
                  mean.model = list(armaOrder = c(0, 0),include.mean = FALSE),
                  distribution.model = "norm")
  garch<-ugarchfit(spec = spec, data = r, solver = 'hybrid', fit.control = list(stationarity = 1))

  ARCH_infty <- optim(par = garch@fit$coef,fn = Loss_ARCH_infty,Y=Y)
  parm<- ARCH_infty$par
  res <- res_ARCH_infty(parm = ARCH_infty$par,Y = Y) # calculate residuals
  Q_tau <- sapply(fixTau, function(x) quantile(res,x))

  return(list("ARCH_par" = parm,"Q_tau"=Q_tau))
}

```


```{r message=FALSE, warning=FALSE}
fixTau <- 141:199/200 # multiple quantile levels

# Calculate the estimates of linear GARCH(1,1) model (2.4) with x_t=y_t using Gaussian QMLE and Q_tau(varepsilon_t) using empirical quantile of {hat{varepsilon}_t} at each quantile levels.
fit_ARCHinfty <- fit_ARCHinfty(Y = Y,fixTau = fixTau)
parm_ARCHinfty <- array(dim = c(length(fixTau),3))
for(tau_index in 1:length(fixTau)){
  tau <- fixTau[tau_index]
  
  par_ARCHinfty_tau <- c(fit_ARCHinfty$ARCH_par[1]/(1-fit_ARCHinfty$ARCH_par[3])*fit_ARCHinfty$Q_tau[tau_index],fit_ARCHinfty$ARCH_par[2]*fit_ARCHinfty$Q_tau[tau_index],fit_ARCHinfty$ARCH_par[3])
  
  parm_ARCHinfty[tau_index,] <- par_ARCHinfty_tau
}

# Obtain parameter estimates and ASDs of the QGARCH(1,1) model using QR estimation at each quantile level
parm_QR <- asd_QR <- array(dim = c(length(fixTau),3))
for(tau_index in 1:length(fixTau)){
  tau <- fixTau[tau_index]

  parm <- fit1_optim(Y = Y,w = w,tau = tau)$par
  Cov <- ASD_QR(parm = parm,Y = Y,w = w,tau = tau,h_type = 'HS')

  parm_QR[tau_index,] <- parm
  asd_QR[tau_index,] <- Cov$ASD
}
```

```{r message=FALSE, warning=FALSE}
# Plot the estimated coefficient functions
par(mfrow = c(1,3),mar=c(4,4,1,1))

index <- length(fixTau)/2

index_parm <- 1
plot(x=fixTau,y=parm_QR[,index_parm],type="l",ylim = c(-0.1,0.8),ylab = "",xlab = expression(tau),main = expression(omega(tau)))
lines(x=fixTau,y=parm_QR[,index_parm]+qnorm(0.975)*asd_QR[,index_parm],col = "black",lty=2)
lines(x=fixTau,y=parm_QR[,index_parm]-qnorm(0.975)*asd_QR[,index_parm],col = "black",lty=2)
lines(x=fixTau,y=parm_ARCHinfty[,index_parm],col = "red",lty=1)

index_parm <- 2
plot(x=fixTau,y=parm_QR[,index_parm],type="l",ylab = "",xlab = expression(tau),main = expression(alpha[1](tau)),ylim = c(0,0.6))
lines(x=fixTau,y=parm_QR[,index_parm]+qnorm(0.975)*asd_QR[,index_parm],col = "black",lty=2)
lines(x=fixTau,y=parm_QR[,index_parm]-qnorm(0.975)*asd_QR[,index_parm],col = "black",lty=2)
lines(x=fixTau,y=parm_ARCHinfty[,index_parm],col = "red",lty=1)

index_parm <- 3
plot(x=fixTau,y=parm_QR[,index_parm],type="l",ylim = c(0.7,0.95),ylab = "",xlab = expression(tau),main = expression(beta[1](tau)))
lines(x=fixTau,y=parm_QR[,index_parm]+qnorm(0.975)*asd_QR[,index_parm],col = "black",lty=2)
lines(x=fixTau,y=parm_QR[,index_parm]-qnorm(0.975)*asd_QR[,index_parm],col = "black",lty=2)
lines(x=fixTau,y=parm_ARCHinfty[,index_parm],col = "red",lty=1)
par(mfrow = c(1,1))
```


## CvM test for constant persistence coefficient

```{r message=FALSE, warning=FALSE}
# Interval 1: [0.7,0.99]
testTau1 <- 141:198/200
K <- length(testTau1)
N <- length(Y)

# Obtain estimates of parameters and Omega_{1w} at multiple quantile levels
parm_multi <- array(NA,dim = c(K,3)) 
Omega_1_multi <- array(NA,dim = c(K,3,3))

for(tau_index in 1:length(testTau1)){
  tau <- testTau1[tau_index]

  result_QR <- fit1_optim(Y = Y,w = w,tau = tau)
  parm <- result_QR$par
  Cov <- ASD_QR(parm = parm,Y = Y,w = w,tau = tau,h_type = "HS")
  
  parm_multi[tau_index,] <- parm
  Omega_1_multi[tau_index,,] <- Cov$Omega_1
}
subsampling_cons_test <- const_test(Y,w,testTau1,parm_multi,Omega_1_multi) # CvM test
subsampling_cons_test[['information']]
```

```{r message=FALSE, warning=FALSE}
# Interval 2: [0.85,0.95]
testTau2 <- 171:190/200
K <- length(testTau2)
N <- length(Y)

# Obtain estimates of parameters and Omega_{1w} at multiple quantile levels
parm_multi <- array(NA,dim = c(K,3))
Omega_1_multi <- array(NA,dim = c(K,3,3))

for(tau_index in 1:length(testTau2)){
  tau <- testTau2[tau_index]

  result_QR <- fit1_optim(Y = Y,w = w,tau = tau)
  parm <- result_QR$par
  Cov <- ASD_QR(parm = parm,Y = Y,w = w,tau = tau,h_type = "HS")
  
  parm_multi[tau_index,] <- parm
  Omega_1_multi[tau_index,,] <- Cov$Omega_1
}
subsampling_cons_test <- const_test(Y,w,testTau2,parm_multi,Omega_1_multi) # CvM test
subsampling_cons_test[['information']]
```


## Forecasting

### Preparation: Backtesting function

```{r}
VaRbacktestB <- function(Hit,VaR,tau,p,Y_true){
  # Define a VaR backtest function
  # ============================================================
  # Hit is a sequence of Hit_t=I(y_t<-VaR_t)
  # VaR is a sequence of Value-at-Risk
  # tau is the quantile level of -VaR=Q_tau(y_t|F_{t-1})
  # p is the dimension of lagged hits in DQ tests
  # ============================================================
  n <- length(Hit) # sample size
  ### Unconditional coverage test
  n1 <- sum(Hit); tauhat <- n1/n
  LR_UC <- -2*log((tau/tauhat)^n1*((1-tau)/(1-tauhat))^(n-n1))
  P.UC <- pchisq(LR_UC,df=1,lower.tail=FALSE) # p-value
  ### Independence test
  ContTable <- table(Hit[-n],Hit[-1])
  if(any(dim(ContTable)!=c(2,2))){LR_Ind=NA;P.Ind = NA}else{
    n00 <- ContTable[1,1]; n01 <- ContTable[1,2]; n10 <- ContTable[2,1]; n11 <- ContTable[2,2]
    tau_null <- (n01+n11)/(n00+n01+n10+n11)
    tau0_alt <- n01/(n00+n01); tau1_alt <- n11/(n10+n11)
    LR_Ind <- -2*log((tau_null/tau0_alt)^n01*(tau_null/tau1_alt)^n11*((1-tau_null)/(1-tau0_alt))^n00*((1-tau_null)/(1-tau1_alt))^n10)
    P.Ind <- pchisq(LR_Ind,df=1,lower.tail=FALSE) # p-value
  }

  ### Conditional coverage test
  if(any(dim(ContTable)!=c(2,2))){
    LR_CC <- NaN
    P.CC <- NaN
  }else{
    LR_CC <- LR_UC+LR_Ind
    P.CC <- pchisq(LR_CC,df=2,lower.tail=FALSE) # p-value
  }
  ### DQ test: hits & lagged VaR
  X <- cbind(1,embed(Hit[-n],p)) # (n-p)*(p+1) matrix
  if(all(dim(ContTable)==c(2,2))){
    if(all(Hit==0)|all(Hit==1)){
      P.DQ <- NaN
    }else{
      if (is.na(det(t(X)%*%X))|det(t(X)%*%X)<=10^{-5}){P.DQ <- NaN
      } else {
        DQ <- t(Hit[(p+1):n]-tau)%*%X%*%solve(t(X)%*%X)%*%t(X)%*%(Hit[(p+1):n]-tau)/tau/(1-tau)
        P.DQ <- pchisq(DQ,df=p+1,lower.tail=FALSE) # p-value
      }
    }
  }else{
    P.DQ <- NaN
  }

  ECR <- mean(Hit)*100
  PE <- sqrt(n)*abs(mean(Hit)-tau)/sqrt(tau*(1-tau))
  Loss <- mean(check_function(x = (Y_true-(-VaR)),tau = tau))
  ###########################################################################
  rbind.data.frame(ECR=ECR,PE=PE,Loss=Loss,UC=P.UC,Ind=P.Ind,CC=P.CC,DQ_comb=P.DQ)  # deparse.level=0
}
```


### Time range 1: 2015/07/01--2021/12/30 (QR)

```{r message=FALSE, warning=FALSE}
N_window <- 1000 # size of the rolling window
N_predict <- length(Y)-N_window # the rest of the data belongs to prediction set
fixTau <- c(0.01,0.025,0.05,0.95,0.975,0.99) # multiple quantile levels

fore_QR <- VaR_forecasting_QR(data = Y,N_train = N_window,fixTau = fixTau) # rolling forecasting based on QR

# Summary the forecasting results
report <- matrix(NA,nrow = 4,ncol = length(fixTau)) # summary table
real <- Y[(N_window+1):(N_window+N_predict)] # true data
for(tau_index in 1:length(fixTau)){
  VaR <- -fore_QR[,tau_index]
  Hit <- real<fore_QR[,tau_index]
  report[,tau_index] <- t(VaRbacktestB(Hit = Hit,VaR = VaR,tau = fixTau[tau_index],p = 4,Y_true = real)[c("ECR","PE","CC","DQ_comb"),])
}
report <- data.frame(round(report,2))
colnames(report) <- as.character(fixTau)
rownames(report) <- c("ECR","PE","CC","DQ_comb")
report
```

### Time range 2: 2000/02/23--2021/12/30 (QR)

```{r}
# Enlarge the out-of-sample set with size 4500
Y <- tail(diff(log(data_ana[,"close"]))*100,5500) # log-return (%)
beg_time <- head(tail(data_ana[-1,"date"],5500),1);beg_time # begin time

N_window <- 1000 # size of the rolling window
N_val <- 500 # size of the length of validation set
N_predict <- length(Y)-N_window-N_val # the rest of the data belongs of prediction set
fixTau <- c(0.001,0.0025,0.005,0.995,0.9975,0.999)
H <- 1:10/100

fore_QR <- VaR_forecasting_QR(data = Y,N_train = N_window,fixTau = fixTau) # rolling forecasting based on QR

# Summary the forecasting results
report <- matrix(NA,nrow = 2,ncol = length(fixTau))
real <- Y[(N_window+N_val+1):(N_window+N_val+N_predict)]
for(tau_index in 1:length(fixTau)){
  VaR <- -fore_QR[(N_val+1):(N_val+N_predict),tau_index]
  Hit <- real<fore_QR[(N_val+1):(N_val+N_predict),tau_index]
  report[,tau_index] <- t(VaRbacktestB(Hit = Hit,VaR = VaR,tau = fixTau[tau_index],p = 4,Y_true = real)[c("ECR","PE"),])
}
report <- data.frame(round(report,2))
colnames(report) <- as.character(fixTau)
rownames(report) <- c("ECR","PE")
report
```

### Time range 2: 2000/02/23--2021/12/30 (CQR)

```{r}
fore_CQR <- VaR_forecasting_CQR(data = Y,N_train = N_window,N_val = N_val,H = H,fixTau = fixTau) #  rolling forecasting based on CQR

# Summary the forecasting results
report <- matrix(NA,nrow = 2,ncol = length(fixTau))
real <- Y[(N_window+N_val+1):(N_window+N_val+N_predict)]
for(tau_index in 1:length(fixTau)){
  VaR <- -fore_CQR[,tau_index]
  Hit <- real<fore_CQR[,tau_index]
  report[,tau_index] <- t(VaRbacktestB(Hit = Hit,VaR = VaR,tau = fixTau[tau_index],p = 4,Y_true = real)[c("ECR","PE"),])
}
report <- data.frame(round(report,2))
colnames(report) <- as.character(fixTau)
rownames(report) <- c("ECR","PE")
report
```
